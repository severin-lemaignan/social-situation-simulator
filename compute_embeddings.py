#! python3

import pandas as pd
import numpy as np
import random
from pathlib import Path
import argparse

random.seed(10)

from langchain.embeddings import OpenAIEmbeddings
from langchain.embeddings import LlamaCppEmbeddings

from analyse import DEFAULT_INTERPOLATION_FREQUENCY, DEFAULT_WINDOW_LENGTH


NAMES = [
    "Oliver",
    "George",
    "William",
    "Jack",
    "James",
    "Thomas",
    "Charlie",
    "Harry",
    "Henry",
    "Alexander",
    "Benjamin",
    "Daniel",
    "Michael",
    "David",
    "Joseph",
    "Matthew",
    "Andrew",
    "Edward",
    "Samuel",
    "Robert",
    "Christopher",
    "Stephen",
    "Richard",
    "Peter",
    "Anthony",
    "Jonathan",
    "Simon",
    "Patrick",
    "Alan",
    "Paul",
    "Nicholas",
    "Timothy",
    "Philip",
    "Francis",
    "Brian",
    "Kevin",
    "Martin",
    "Keith",
    "Graham",
    "Terry",
    "Barry",
    "Derek",
    "Adrian",
    "Wayne",
    "Gary",
    "Stuart",
    "Malcolm",
    "Gavin",
    "Darren",
    "Lee",
    "Olivia",
    "Amelia",
    "Isla",
    "Ava",
    "Emily",
    "Sophia",
    "Lily",
    "Isabella",
    "Mia",
    "Poppy",
    "Ella",
    "Grace",
    "Freya",
    "Scarlett",
    "Chloe",
    "Daisy",
    "Alice",
    "Phoebe",
    "Matilda",
    "Charlotte",
    "Jessica",
    "Lucy",
    "Rosie",
    "Hannah",
    "Ruby",
    "Evelyn",
    "Zoe",
    "Abigail",
    "Erin",
    "Eleanor",
    "Megan",
    "Elizabeth",
    "Victoria",
    "Laura",
    "Rachel",
    "Rebecca",
    "Nicola",
    "Louise",
    "Jennifer",
    "Susan",
    "Karen",
    "Christine",
    "Pamela",
    "Wendy",
    "Angela",
    "Alison",
    "Sharon",
    "Donna",
    "Sandra",
    "Diane",
]


def realise_names(desc):

    mapping = {k: random.choice(NAMES) for k in "ABCDEFGHIJKLMNOPQRSTUVW"}

    return [d.format(**mapping) for d in desc]


def generate_variations(desc, max=5):

    # add variations of the same description
    tokens = [x.strip() for x in desc.split(";")]

    variations = []

    for _ in range(max):
        random.shuffle(tokens)
        variation = "; ".join(tokens)
        if variation not in variations and variation != desc:
            variations.append(variation)

    return variations


if __name__ == "__main__":

    parser = argparse.ArgumentParser(
        description="Extract social scene descriptions and compute corresponding embeddings"
    )
    parser.add_argument(
        "-s",
        "--sampling-rate",
        type=float,
        nargs="?",
        default=DEFAULT_INTERPOLATION_FREQUENCY,
        help="(Hz) resampling rate of the situation. Default to %sHz."
        % DEFAULT_INTERPOLATION_FREQUENCY,
    )
    parser.add_argument(
        "-l",
        "--window-length",
        type=float,
        nargs="?",
        default=DEFAULT_WINDOW_LENGTH,
        help="(secs) length of the window for which descriptions are generated before each point. Default to %ss."
        % DEFAULT_WINDOW_LENGTH,
    )

    parser.add_argument(
        "src",
        type=str,
        help="CSV file containing all the situation descriptions, as generated by analyse.py",
    )

    parser.add_argument(
        "dest",
        type=str,
        help="CSV file containing the computed embeddings. If the file already exists, embeddings for new descriptions will be added to it.",
    )

    args = parser.parse_args()

    embeddings_model = OpenAIEmbeddings()
    # embeddings_model = LlamaCppEmbeddings(
    #    model_path="/home/severinlemaignan/src/llama.cpp/models/llama-2-13b-chat.ggmlv3.q4_0.bin"
    # )

    df = pd.read_csv(args.src)

    # pre-load previous embeddings
    if Path(args.dest).exists():
        print("%s already exist. Adding new embeddings to it." % args.dest)
        embeddings_df = pd.read_csv(args.dest, index_col=0)
        embeddings = {
            row["template"]: row.to_dict() for _, row in embeddings_df.iterrows()
        }
    else:
        embeddings = {}

    ts = np.arange(0, args.window_length + 0.001, 1 / args.sampling_rate)

    groups = []
    all_descriptions = list(embeddings.keys())

    for _, row in df.iterrows():

        engaged = row["engaged"]
        actual_ts = row["actual_ts"]
        viewed_by = row["viewed_by"]
        for t in ts:
            desc = row["t-%s" % t]

            if desc not in groups:
                groups.append(desc)

            group_id = groups.index(desc)

            variations = [desc] + generate_variations(desc)

            for desc in variations:
                if desc in all_descriptions:
                    continue

                all_descriptions.append(desc)

                if desc not in embeddings:
                    print("Computing embedding of %s..." % desc)
                    realised_desc, realised_viewed = realise_names([desc, viewed_by])
                    # emb = embeddings_model.embed_query(realised_desc)
                    emb = [1, 1, 1, 1]

                    embeddings[desc] = {
                        "group": group_id,
                        "engaged": engaged if t == 0.0 else 0,
                        "ts": actual_ts - t,
                        "viewed_by": viewed_by,
                        "viewed_by_name": realised_viewed,
                        "template": desc,
                        "desc": realised_desc,
                    }
                    for i, v in enumerate(emb):
                        embeddings[desc][str(i)] = v
                else:
                    # do not recomputed the embedding, but update the 'engaged' status if it is 'true'
                    if t == 0.0 and engaged:
                        embeddings[desc]["engaged"] = engaged

    df_embeddings = pd.DataFrame.from_dict(embeddings, orient="index").reset_index(
        drop=True
    )
    df_embeddings.to_csv(args.dest)

    print("Successfully saved embeddings to %s" % args.dest)

    # print(df_embeddings)

    # for g in groups:
    #    print(g)
